import pandas as pd
import re
import requests
import time
import random
import os
from dotenv import load_dotenv
from tqdm import tqdm
import concurrent.futures

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
KAKAO_API_KEY = os.getenv("KAKAO_API_KEY")
headers = {"Authorization": f"KakaoAK {KAKAO_API_KEY}"}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. ì£¼ì†Œ ì •ì œ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def clean_address(addr):
    if pd.isna(addr):
        return ""
    addr = str(addr)
    addr = re.sub(r"\s*\([^)]*\)", "", addr)
    if "," in addr:
        addr = addr.split(",")[0].strip()
    return addr.strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. ì¹´ì¹´ì˜¤ API ìš”ì²­ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_lat_lon_retry(address, retry=3):
    for _ in range(retry):
        try:
            time.sleep(random.uniform(0.1, 0.3))
            url = "https://dapi.kakao.com/v2/local/search/address.json"
            params = {"query": address, "analyze_type": "exact"}
            res = requests.get(url, headers=headers, params=params, timeout=5)
            if res.status_code != 200:
                continue
            documents = res.json().get("documents", [])
            if not documents:
                continue
            x = float(documents[0]["x"])
            y = float(documents[0]["y"])
            return y, x
        except:
            continue
    return None, None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. ë³‘ë ¬ ì²˜ë¦¬ (ìˆœì„œ ë³´ì¥) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parallel_geocode_ordered(address_list, max_workers=20):
    results = [None] * len(address_list)
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_index = {
            executor.submit(get_lat_lon_retry, addr): idx
            for idx, addr in enumerate(address_list)
        }
        for future in tqdm(concurrent.futures.as_completed(future_to_index), total=len(address_list), desc="ğŸ“ ë³‘ë ¬ ìœ„ê²½ë„ ë³€í™˜"):
            idx = future_to_index[future]
            try:
                results[idx] = future.result()
            except:
                results[idx] = (None, None)
    return results

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. ë©”ì¸ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    df = pd.read_csv("../../pages/hospital_combined.csv").dropna(subset=["address"]).copy()

    df["cleaning"] = df["address"].apply(clean_address)
    coords = parallel_geocode_ordered(df["cleaning"].tolist(), max_workers=20)
    df["lat"], df["lon"] = zip(*coords)

    # ğŸ” 6. ë§¤ì¹­ í™•ì¸ìš© ë¡œê·¸ 5ê°œ ì¶œë ¥
    print("\nğŸ“Œ [ì£¼ì†Œ â†” ìœ„ê²½ë„ ë§¤ì¹­ í™•ì¸]")
    print(df[["address", "cleaning", "lat", "lon"]].head(5).to_string(index=False))

    # 7. ì„±ê³µ/ì‹¤íŒ¨ ë¶„ë¦¬
    success_df = df[df["lat"].notna() & df["lon"].notna()].copy()
    fail_df = df[df["lat"].isna() | df["lon"].isna()].copy()

    # 8. ì €ì¥
    fail_df.to_csv("missing_hospitals_failed.csv", index=False)
    success_df.drop(columns=["cleaning"], inplace=True)
    success_df.to_csv("missing_hospitals_success.csv", index=False)

    # 9. ë¡œê·¸
    print(f"\nâœ… ë³€í™˜ ì„±ê³µ: {len(success_df)}ê±´")
    print(f"âŒ ë³€í™˜ ì‹¤íŒ¨: {len(fail_df)}ê±´")

